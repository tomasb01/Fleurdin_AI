"""
FLEURDIN AI - PARSING SCRIPT
=============================
Naƒçte zdrojov√© soubory a vytvo≈ô√≠ ƒçist√© stringy.
"""

import pandas as pd
import json
from docx import Document
from pathlib import Path

# Cesty ke zdrojov√Ωm soubor≈Øm
BASE_PATH = Path("/Users/atlas/Projects/Fleurdin_AI/2-Dataset/2-1-Raw_data")

# Esenci√°ln√≠ oleje
OILS_FILE = BASE_PATH / "Fleurdin/EO_prehled oleju_30oils_updated.csv.xlsx"

# Bylinky
BYLINKY_PATH = BASE_PATH / "Bylinky_DivokaStrava/Data"
BOOK1_FILE = BYLINKY_PATH / "Lieƒçiv√° sila divok√Ωch byliniek_po RU_1.2.2023.docx"
BOOK2_FILE = BYLINKY_PATH / "kniha2_hlavny text_rkp_NP_uprava 22-1-25.docx"
DRIENKY_FILE = BYLINKY_PATH / "DRIENKY.docx"

# V√Ωstup
OUTPUT_FILE = Path("/Users/atlas/Projects/Fleurdin_AI/4-RAG_Pipeline/parsed_data.json")


print("="*70)
print("üöÄ FLEURDIN AI - PARSING ZAƒå√çN√Å")
print("="*70)
  
def parse_essential_oils(excel_path):
    """
    Naƒçte Excel s esenci√°ln√≠mi oleji a vr√°t√≠ ƒçist√© stringy
    """
    print("\nüì¶ PARSING: Esenci√°ln√≠ oleje")
      
    print("-" * 70)

    # Naƒçti Excel
    df = pd.read_excel(excel_path)

    oils = []

    # Projdi ≈ô√°dky (od ≈ô√°dku 2, proto≈æe prvn√≠ 2 jsou hlaviƒçka)
    for idx, row in df.iterrows():
        if idx < 2:  # P≈ôeskoƒç hlaviƒçku
            continue

        # P≈ôeƒçti data z ≈ô√°dku
        oil_id = row.iloc[0]
        name = row.iloc[1]
        english_name = row.iloc[2]
        latin_name = row.iloc[3]
        frequency = row.iloc[4]
        body_effects = str(row.iloc[5]) if pd.notna(row.iloc[5]) else ""
        psyche_effects = str(row.iloc[6]) if pd.notna(row.iloc[6]) else ""

        # P≈ôeskoƒç pr√°zdn√© ≈ô√°dky
        if pd.isna(name) or name == "":
            continue

        # Vytvo≈ô ƒçist√Ω string (text chunk)
        text = f"""OLEJ: {name}

√öƒåINKY NA TƒöLO:
{body_effects}

√öƒåINKY NA PSYCHIKU:
{psyche_effects}"""

        # Ulo≈æ jako dictionary
        oil_data = {
            "id": f"oil_{int(oil_id) if pd.notna(oil_id) else idx}",
            "type": "essential_oil",
            "name": name,
            "text": text,
            "metadata": {
                "english_name": english_name if pd.notna(english_name) else "",
                "latin_name": latin_name if pd.notna(latin_name) else "",
                "frequency": frequency if pd.notna(frequency) else ""
            }
        }

        oils.append(oil_data)
        print(f"  ‚úÖ {name}")

    print(f"\n  üìä Celkem naƒçteno: {len(oils)} olej≈Ø")
    return oils
    
def parse_word_document(doc_path, doc_name):
    """
    Naƒçte Word dokument a vr√°t√≠ odstavce jako stringy
    """
    print(f"\nüì¶ PARSING: {doc_name}")
    print("-" * 70)

    # Naƒçti Word dokument
    doc = Document(doc_path)

    paragraphs = []

    # Projdi v≈°echny odstavce
    for i, para in enumerate(doc.paragraphs):
        text = para.text.strip()

        # P≈ôeskoƒç pr√°zdn√© odstavce
        if not text or len(text) < 10:
            continue

        # Ulo≈æ odstavec
        para_data = {
            "id": f"{doc_name}_para_{i+1}",
            "type": "paragraph",
            "text": text,
            "metadata": {
                "source": doc_name,
                "paragraph_number": i+1
            }
        }

        paragraphs.append(para_data)

    print(f"  üìä Celkem naƒçteno: {len(paragraphs)} odstavc≈Ø")
    print(f"  üìè Celkov√° d√©lka: {sum(len(p['text']) for p in paragraphs):,} znak≈Ø")

    return paragraphs
    
def main():
    """
    Hlavn√≠ funkce - spust√≠ parsing v≈°ech soubor≈Ø
    """

    # 1. Parse esenci√°ln√≠ oleje
    oils = parse_essential_oils(OILS_FILE)

    # 2. Parse knihu 1
    book1 = parse_word_document(BOOK1_FILE, "book1")

    # 3. Parse knihu 2
    book2 = parse_word_document(BOOK2_FILE, "book2")

    # 4. Parse DRIENKY (voice p≈ôepis)
    drienky = parse_word_document(DRIENKY_FILE, "drienky")

    # Spoj v≈°echno dohromady
    all_data = {
        "essential_oils": oils,
        "book1": book1,
        "book2": book2,
        "drienky": drienky,
        "stats": {
            "total_items": len(oils) + len(book1) + len(book2) + len(drienky),
            "essential_oils_count": len(oils),
            "book1_count": len(book1),
            "book2_count": len(book2),
            "drienky_count": len(drienky)
        }
    }

    # Ulo≈æ do JSON
    print("\n" + "="*70)
    print("üíæ UKL√ÅD√ÅM DATA")
    print("="*70)

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ HOTOVO!")
    print(f"üìÇ V√Ωstup: {OUTPUT_FILE}")
    print(f"\nüìä STATISTIKY:")
    print(f"  ‚Ä¢ Esenci√°ln√≠ oleje: {len(oils)}")
    print(f"  ‚Ä¢ Kniha 1: {len(book1)} odstavc≈Ø")
    print(f"  ‚Ä¢ Kniha 2: {len(book2)} odstavc≈Ø")
    print(f"  ‚Ä¢ DRIENKY: {len(drienky)} odstavc≈Ø")
    print(f"  ‚Ä¢ CELKEM: {all_data['stats']['total_items']} polo≈æek")
    print("\n" + "="*70)

# Spus≈• program
if __name__ == "__main__":
    main()